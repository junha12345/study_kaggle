1) Scaling
일반적으로 데이터의 범위를 임의로 조정하는 것을 의미합니다.
데이터 분포의 모양은 변하지않고 기존 데이터와 동일한 비율을 유지한 채 범위를 조정합니다.
사용목적 : 독립된 여러 개의 변수를 사용할 때 각 변수 별로 단위가 다를 경우, 학습 시에 미치는 중요도가 달라지는 문제를 방지할 수 있습니다.
    A) Min Max
    최소 값은 0 최대 값은 1으로, 모든 데이터가 [0, 1] 범위안에 들어가도록 조절하는 기법입니다.
    
    B) Max Abs
    절댓값이 가장 큰 수의 절대값으로 전체를 나누어 모든 데이터의 범위를 [-1, 1 ]으로 조절하는 기법입니다.
    
    C) Robust
     중앙값과 IQR을 활용하여 아웃라이어의 영향을 적게 받는 것이 특징인 기법입니다.
    
    D) Standard
    Z-Score Normalization와 같은 기법입니다.
    (C, D는 Scaling의 범주로 보기 힘들고 보통 Standardization으로 본다)
    
2) Standardization
일반적으로 평균으로 구한 분포의 표준 편차를 1로 맞추기 위해 데이터를 바꾸는 것을 의미합니다.
각 feature 간의 상대적 거리를 왜곡시킬 수 있는 점을 고려하여 사용해야 합니다.
사용목적 : 정규분포를 표준 정규분포로 변환시켜주어 서로 다른 자료들을 쉽게 비교 분석할 수 있도록 만들어 줍니다.
    A) Z-Score Normalization
    데이터를 평균 0, 표준편차 1인 표준정규분포로 만들어주는 기법입니다.

3) Regularization
일반적으로 가중치를 조정할 때 추가적인 제약을 주는 것을 의미합니다.
사용목적 : 학습 데이터에 대한 민감도를 낮춰줍니다.
    A) Ridge
    L2 norm을 사용하여 가중치에 규제를 가하는 기법입니다.
    
    B) Lasso
    L1 norm을 사용하여 가중치에 규제를 가하는 기법입니다.

    C) Elastic Net
    Ridge와 Lasso 두 방법론을 혼합한 유형입니다.
    
이외에도 여러가지 방법들이 존재 but 무수히 많음
